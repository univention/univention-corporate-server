#!/usr/bin/env python3
# vim:set fileencoding=utf-8 expandtab shiftwidth=4 tabstop=4:
"""
Generate Gitlab pipeline to build UCS documentation.

Author: Philipp Hahn 2024-03-13
"""

from __future__ import annotations

import argparse
from pathlib import Path

from ruamel.yaml import YAML


BASE = Path(__file__).parent  # .gilab-ci/
ROOT = BASE.parent


TARGETS = ["html", "pdf", "linkcheck", "spelling"]
DEPENDS = {
    "app-center": {"manual", "developer-reference cycle"},
    "architecture": {"manual", "developer-reference cycle", "app-center"},
    "debian-admins": {"manual", "architecture"},
    "developer-reference": {"app-center", "architecture", "manual"},
    "ext-domain": {"manual"},
    "ext-networks": {"manual"},
    "ext-performance": {"manual", "developer-reference"},
    "ext-windows": {"manual"},
    "manual": {"developer-reference cycle", "ext-windows cycle"},
    "quickstart": {"manual", "ext-domain", "ext-installation"},
    "release-notes": {"manual", "changelog", "ext-windows"},
    "scenarios": {"manual"},
}  # FIXME: extract this from ../doc/*/conf.py intersphinx_mapping
SPECIAL: dict[str, dict[str, object]] = {
    "changelog": {"DOC_TARGET_PATH": "$DOC_TARGET_NAME/$CHANGELOG_TARGET_VERSION/$language"},
    "release-notes": {"DOC_TARGET_PATH": "$DOC_TARGET_NAME/$CHANGELOG_TARGET_VERSION/$language"},
    "developer-reference cycle": {"SPHINXOPTS": "--keep-going"},
    "ext-windows cycle": {"SPHINXOPTS": "--keep-going"},
}


all_paths: list[str] = []
pipeline: dict[str, object] = {
    "docs-merge-to-one-artifact": {
        "extends": ".sphinx-merge-template",
        "rules": [
            {
                "if": '$CI_COMMIT_REF_PROTECTED == "true" || $CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "webide"',
                "changes": all_paths,
                "when": "manual",
            },
            {
                "if": '$CI_COMMIT_REF_PROTECTED == "false" || $CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "webide"',
                "changes": all_paths,
            },
        ],
    },
    "docs-create-production-merge-request": {
        "extends": ".sphinx-docs-merge-request-template",
        "needs": [
            {"job": "docs-merge-to-one-artifact"},
        ],
        "rules": [
            {
                "if": '$CI_COMMIT_REF_PROTECTED == "true" || $CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "webide"',
                "changes": all_paths,
            },
        ],
    },
}


def main() -> None:
    args = parse_args()

    yaml = YAML(typ="rt")
    for head in args.yaml:
        with head.open() as fd:
            data = yaml.load(fd)
        pipeline.update(data)

    add_jobs(pipeline)

    with args.out.open("w") as fd:
        yaml.dump(pipeline, fd)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("--yaml", action="append", type=Path, default=[])
    parser.add_argument("--out", type=Path, default=ROOT / "generated-config-doc.yml")
    return parser.parse_args()


def job_name(pkg: str, target: str = "") -> str:
    return f"build {pkg}{f' {target}' if target else ''}"


def job_desc(pkg: str, path: Path, extends: str, languages: list[str], depends: set[str]) -> dict[str, object]:
    variables = dict(
        SPECIAL.get(pkg, {}),
        DOCS_DIR=path.relative_to(ROOT).as_posix(),
        DOC_TARGET_NAME=path.name,
        # For special documents we need to overwrite the default DOC_TARGET_PATH and pull the value from the SPECIAL dict.
        DOC_TARGET_PATH=SPECIAL.get(pkg, {}).get("DOC_TARGET_PATH", None) or "$DOC_TARGET_NAME/$DOC_TARGET_VERSION/$language",
    )
    job: dict[str, object] = {
        "variables": variables,
        "extends": extends,
        "rules": [
            {
                "if": "$CI_COMMIT_MESSAGE =~ /skip-doc/ || $pipeline =~ /skip-doc/",
                "when": "never",
            },
            {
                "if": "$CI_COMMIT_MESSAGE =~ /force-doc/ || $pipeline =~ /force-doc/",
            },
            {
                "changes": [
                    job_path(path),
                ],
            },
        ],
        "parallel": {
            "matrix": [
                {"language": languages},
            ],
        },
    }
    if depends:
        job["needs"] = [
            {
                "job": job_name(dep, "html"),
                "optional": True,
            }
            for dep in depends
        ]

    return job


def job_path(path: Path) -> str:
    return f"{path.relative_to(ROOT).as_posix()}/**/*"


def find_docs() -> dict[Path, list[str]]:
    return {
        path.parent: list({lang.name for lang in path.parent.glob("locales/*")} | {"en"})
        for path in ROOT.glob("doc/*/conf.py")
    }


def add_jobs(pipeline: dict[str, object]) -> None:
    docs = find_docs()
    for path, languages in docs.items():
        all_paths.append(job_path(path))
        for target in TARGETS:
            pkg = path.name
            name = job_name(pkg, target)
            job = job_desc(pkg, path, f".sphinx-{target}", languages, DEPENDS.get(pkg, set()))
            pipeline.update({name: job})

    # FIXME: cycle
    path = ROOT / "doc" / "developer-reference"
    pkg = f"{path.name} cycle"
    name = job_name(pkg, "html")
    job = job_desc(pkg, path, ".sphinx-html", ["en"], set())
    pipeline.update({name: job})


if __name__ == "__main__":
    main()
